{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# GDS\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "from shapely import wkt\n",
    "\n",
    "# network\n",
    "import networkx as nx\n",
    "import powerlaw\n",
    "\n",
    "from my_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3.0\n"
     ]
    }
   ],
   "source": [
    "print(VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_odRegion = pd.read_csv(f\"result/df_tf_odRegion_{VERSION}.csv\")\n",
    "gdf_zoning = read_csv_to_gdf(f\"result/gdf_zoning_{VERSION}.csv\").to_crs(\"epsg:2263\")\n",
    "df_zonevec = pd.read_csv(f\"result/df_zonevec_{VERSION}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set(df_zonevec.id.values) & set(df_tf_odRegion.Destiny_ID.unique()) & set(df_tf_odRegion.Origin_ID.unique())\n",
    "dict_mapids = {x:i for i,x in enumerate(ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to new regin id\n",
    "df_tf_odRegionN = df_tf_odRegion.copy()\n",
    "df_tf_odRegionN[\"Origin_ID\"] = df_tf_odRegionN[\"Origin_ID\"].apply(lambda x:dict_mapids[x] if x in dict_mapids.keys() else -1)\n",
    "df_tf_odRegionN[\"Destiny_ID\"] = df_tf_odRegionN[\"Destiny_ID\"].apply(lambda x:dict_mapids[x] if x in dict_mapids.keys() else -1)\n",
    "\n",
    "# drop invalid regions\n",
    "df_tf_odRegionN = df_tf_odRegionN[(df_tf_odRegionN[\"Origin_ID\"]!=-1).values & (df_tf_odRegionN[\"Destiny_ID\"]!=-1).values] \\\n",
    "                    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12252985, 12637248)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tf_odRegionN),len(df_tf_odRegion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tf_odRegionN = df_tf_odRegionN.assign(time= lambda x:(x[\"dayofmonth\"]-1)*24+x[\"hour\"]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_odRegionN = df_tf_odRegionN.assign(time= lambda x:(x[\"weekend\"])*24+x[\"hour\"]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flowcount = pd.pivot_table(df_tf_odRegionN[['Origin_ID', 'Destiny_ID', 'time','pasg']],\n",
    "                              values='pasg', index=['Origin_ID', 'Destiny_ID'],\n",
    "                              columns='time', aggfunc=np.sum) \\\n",
    "                .fillna(0) \\\n",
    "                .astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origin_ID</th>\n",
       "      <th>Destiny_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>1975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "time                  1   2   3   4   5   6   7   8   9   10  ...  39  40  41  \\\n",
       "Origin_ID Destiny_ID                                          ...               \n",
       "0         1975         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   \n",
       "1         2220         0   0   0   0   0   0   0   1   0   0  ...   0   0   0   \n",
       "2         2            0   0   0   0   0   0   0   0   0   0  ...   0   0   0   \n",
       "          995          0   0   0   0   0   0   0   0   0   0  ...   0   0   0   \n",
       "          2220         0   0   0   0   0   0   2   0   0   0  ...   0   0   0   \n",
       "\n",
       "time                  42  43  44  45  46  47  48  \n",
       "Origin_ID Destiny_ID                              \n",
       "0         1975         0   0   0   0   0   0   0  \n",
       "1         2220         0   0   0   0   0   0   0  \n",
       "2         2            0   0   0   0   0   0   0  \n",
       "          995          0   0   0   0   0   0   0  \n",
       "          2220         0   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flowcount.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tobeadd = set((i,i) for i in dict_mapids.values()) - set(df_flowcount.index)\n",
    "index_tobeadd = np.array([list(i) for i in index_tobeadd])\n",
    "df_flow_tobeadd = pd.DataFrame(columns = [i+1 for i in range(48)], \n",
    "                               index = pd.MultiIndex.from_arrays(np.array(index_tobeadd).T, \n",
    "                                                                 names=('Origin_ID', 'Destiny_ID'))) \\\n",
    "                    .fillna(0)\n",
    "\n",
    "df_flowcount_filled = pd.concat([df_flowcount,df_flow_tobeadd]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flowcount_filled.to_csv(f\"result/df_flowcount_filled_{VERSION}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flowcount_filled = pd.read_csv(f\"result/df_flowcount_filled_{VERSION}.csv\").set_index(['Origin_ID', 'Destiny_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "def fourier(x, *a):\n",
    "    w = 2 * np.pi / 48\n",
    "    ret = 0\n",
    "    for deg in range(0, int(len(a) / 2) + 1):\n",
    "        ret += a[deg] * np.cos(deg * w * x) + a[len(a) - deg - 1] * np.sin(deg * w * x)\n",
    "    return ret\n",
    "\n",
    "def fft(y):\n",
    "    x = np.arange(1,49,1)\n",
    "    popt, pcov = curve_fit(fourier, x, y, [1.0] * 20)\n",
    "    return popt.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "505766it [59:07, 142.58it/s]\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "for i,row in tqdm.tqdm(df_flowcount_filled.iterrows()):\n",
    "    dic[i] = fft(row.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = pd.DataFrame.from_dict(dic).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges.to_csv(f\"result/df_edges_{VERSION}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"result/dic\",dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fft back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.54167, -6.73017,  0.17043, -4.97363,  3.70264,  2.8315 ,\n",
       "        6.4379 , -0.68115, -2.33333, -1.41855, -1.0891 ,  0.21651,\n",
       "        5.15297,  3.1297 , -2.56709, -4.15799, -2.05386, -6.30115,\n",
       "       13.17348,  1.     ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efeats[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = -11\n",
    "\n",
    "y = df_flowcount_filled.iloc[idx]\n",
    "x = np.arange(1,49,1)\n",
    "# popt, pcov = curve_fit(fourier, x, y, [1.0] * 20)\n",
    "plt.plot(x, y, color='r', label=\"original\")\n",
    "plt.plot(x, fourier(x, *efeats[idx]), color='g', label=\"fitting\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 两种思路 时序预测\n",
    "* 时序特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_odRegion = pd.read_csv(f\"result/df_tf_odRegion_{VERSION}.csv\")\n",
    "gdf_zoning = read_csv_to_gdf(f\"result/gdf_zoning_{VERSION}.csv\").to_crs(\"epsg:2263\")\n",
    "df_zonevec = pd.read_csv(f\"result/df_zonevec_{VERSION}.csv\")\n",
    "\n",
    "ids = set(df_zonevec.id.values) & set(df_tf_odRegion.Destiny_ID.unique()) & set(df_tf_odRegion.Origin_ID.unique())\n",
    "dict_mapids = {x:i for i,x in enumerate(ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = pd.read_csv(f\"result/df_edges_{VERSION}.csv\").set_index(['Unnamed: 0', 'Unnamed: 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zonevec[\"new_id\"] = df_zonevec[\"id\"].apply(lambda x:dict_mapids[x] if x in dict_mapids.keys() else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zonevecN = df_zonevec[df_zonevec.new_id!=-1].drop(\"id\",axis=1).set_index(\"new_id\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [list(i) for i in df_edges.index]\n",
    "nodes = [i for i in range(len(dict_mapids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "edgeid_to_idx = defaultdict(set)\n",
    "adj_lists = defaultdict(set)\n",
    "\n",
    "for i,e in enumerate(edges):\n",
    "    edgeid_to_idx[tuple(e)] = i\n",
    "    u,v =e\n",
    "    adj_lists[u].add(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeats = np.array(df_zonevecN.loc[:,[f\"ZoneVec_{i+1}\" for i in range(20)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "efeats = df_edges.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.GraphSAGE import *\n",
    "import torch\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "nfeats1 = torch.tensor(nfeats).float().to(device)\n",
    "efeats1 = torch.tensor(efeats).float().to(device)\n",
    "nodes = nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------EPOCH 0-----------------------\n",
      "Step [1/271], Loss: 3.1430, Dealed Nodes [67/2709] \n",
      "Step [2/271], Loss: 3.1622, Dealed Nodes [119/2709] \n",
      "Step [3/271], Loss: 3.1044, Dealed Nodes [169/2709] \n",
      "Step [4/271], Loss: 3.0898, Dealed Nodes [218/2709] \n",
      "Step [5/271], Loss: 3.0458, Dealed Nodes [260/2709] \n",
      "Step [6/271], Loss: 3.0864, Dealed Nodes [296/2709] \n",
      "Step [7/271], Loss: 3.0985, Dealed Nodes [343/2709] \n",
      "Step [8/271], Loss: 3.0781, Dealed Nodes [385/2709] \n",
      "Step [9/271], Loss: 3.0628, Dealed Nodes [422/2709] \n",
      "Step [10/271], Loss: 3.0722, Dealed Nodes [458/2709] \n",
      "Step [11/271], Loss: 3.0797, Dealed Nodes [489/2709] \n",
      "Step [12/271], Loss: 3.0642, Dealed Nodes [528/2709] \n",
      "Step [13/271], Loss: 3.0691, Dealed Nodes [575/2709] \n",
      "Step [14/271], Loss: 3.0605, Dealed Nodes [606/2709] \n",
      "Step [15/271], Loss: 3.0628, Dealed Nodes [643/2709] \n",
      "Step [16/271], Loss: 3.0788, Dealed Nodes [678/2709] \n",
      "Step [17/271], Loss: 3.0473, Dealed Nodes [709/2709] \n",
      "Step [18/271], Loss: 3.0347, Dealed Nodes [733/2709] \n",
      "Step [19/271], Loss: 3.0482, Dealed Nodes [766/2709] \n",
      "Step [20/271], Loss: 3.0494, Dealed Nodes [794/2709] \n",
      "Step [21/271], Loss: 3.0507, Dealed Nodes [827/2709] \n",
      "Step [22/271], Loss: 3.0409, Dealed Nodes [858/2709] \n",
      "Step [23/271], Loss: 3.0506, Dealed Nodes [888/2709] \n",
      "Step [24/271], Loss: 3.0365, Dealed Nodes [924/2709] \n",
      "Step [25/271], Loss: 3.0350, Dealed Nodes [944/2709] \n",
      "Step [26/271], Loss: 3.0262, Dealed Nodes [972/2709] \n",
      "Step [27/271], Loss: 3.0298, Dealed Nodes [999/2709] \n",
      "Step [28/271], Loss: 3.0429, Dealed Nodes [1020/2709] \n",
      "Step [29/271], Loss: 3.0294, Dealed Nodes [1042/2709] \n",
      "Step [30/271], Loss: 3.0366, Dealed Nodes [1064/2709] \n",
      "Step [31/271], Loss: 3.0438, Dealed Nodes [1083/2709] \n",
      "Step [32/271], Loss: 3.0382, Dealed Nodes [1101/2709] \n",
      "Step [33/271], Loss: 3.0472, Dealed Nodes [1126/2709] \n",
      "Step [34/271], Loss: 3.0370, Dealed Nodes [1146/2709] \n",
      "Step [35/271], Loss: 3.0330, Dealed Nodes [1170/2709] \n",
      "Step [36/271], Loss: 3.0289, Dealed Nodes [1192/2709] \n",
      "Step [37/271], Loss: 3.0283, Dealed Nodes [1208/2709] \n",
      "Step [38/271], Loss: 3.0298, Dealed Nodes [1227/2709] \n",
      "Step [39/271], Loss: 3.0366, Dealed Nodes [1248/2709] \n",
      "Step [40/271], Loss: 3.0281, Dealed Nodes [1270/2709] \n",
      "Step [41/271], Loss: 3.0384, Dealed Nodes [1289/2709] \n",
      "Step [42/271], Loss: 3.0495, Dealed Nodes [1313/2709] \n",
      "Step [43/271], Loss: 3.0160, Dealed Nodes [1334/2709] \n",
      "Step [44/271], Loss: 3.0247, Dealed Nodes [1352/2709] \n",
      "Step [45/271], Loss: 3.0409, Dealed Nodes [1377/2709] \n",
      "Step [46/271], Loss: 3.0278, Dealed Nodes [1391/2709] \n",
      "Step [47/271], Loss: 3.0353, Dealed Nodes [1408/2709] \n",
      "Step [48/271], Loss: 3.0234, Dealed Nodes [1422/2709] \n",
      "Step [49/271], Loss: 3.0329, Dealed Nodes [1440/2709] \n",
      "Step [50/271], Loss: 3.0199, Dealed Nodes [1456/2709] \n",
      "Step [51/271], Loss: 3.0308, Dealed Nodes [1472/2709] \n",
      "Step [52/271], Loss: 3.0246, Dealed Nodes [1490/2709] \n",
      "Step [53/271], Loss: 3.0222, Dealed Nodes [1502/2709] \n",
      "Step [54/271], Loss: 3.0268, Dealed Nodes [1512/2709] \n",
      "Step [55/271], Loss: 3.0214, Dealed Nodes [1531/2709] \n",
      "Step [56/271], Loss: 3.0194, Dealed Nodes [1546/2709] \n",
      "Step [57/271], Loss: 3.0218, Dealed Nodes [1557/2709] \n",
      "Step [58/271], Loss: 3.0222, Dealed Nodes [1575/2709] \n",
      "Step [59/271], Loss: 3.0263, Dealed Nodes [1586/2709] \n",
      "Step [60/271], Loss: 3.0124, Dealed Nodes [1601/2709] \n",
      "Step [61/271], Loss: 3.0210, Dealed Nodes [1613/2709] \n",
      "Step [62/271], Loss: 3.0256, Dealed Nodes [1624/2709] \n",
      "Step [63/271], Loss: 3.0276, Dealed Nodes [1640/2709] \n",
      "Step [64/271], Loss: 3.0220, Dealed Nodes [1655/2709] \n",
      "Step [65/271], Loss: 3.0255, Dealed Nodes [1668/2709] \n",
      "Step [66/271], Loss: 3.0259, Dealed Nodes [1680/2709] \n",
      "Step [67/271], Loss: 3.0189, Dealed Nodes [1691/2709] \n",
      "Step [68/271], Loss: 3.0126, Dealed Nodes [1705/2709] \n",
      "Step [69/271], Loss: 3.0215, Dealed Nodes [1716/2709] \n",
      "Step [70/271], Loss: 3.0181, Dealed Nodes [1730/2709] \n",
      "Step [71/271], Loss: 3.0363, Dealed Nodes [1739/2709] \n",
      "Step [72/271], Loss: 3.0204, Dealed Nodes [1745/2709] \n",
      "Step [73/271], Loss: 3.0169, Dealed Nodes [1759/2709] \n",
      "Step [74/271], Loss: 3.0210, Dealed Nodes [1775/2709] \n",
      "Step [75/271], Loss: 3.0225, Dealed Nodes [1784/2709] \n",
      "Step [76/271], Loss: 3.0209, Dealed Nodes [1796/2709] \n",
      "Step [77/271], Loss: 3.0155, Dealed Nodes [1806/2709] \n",
      "Step [78/271], Loss: 3.0114, Dealed Nodes [1813/2709] \n",
      "Step [79/271], Loss: 3.0252, Dealed Nodes [1822/2709] \n",
      "Step [80/271], Loss: 3.0179, Dealed Nodes [1838/2709] \n",
      "Step [81/271], Loss: 3.0125, Dealed Nodes [1846/2709] \n",
      "Step [82/271], Loss: 3.0112, Dealed Nodes [1855/2709] \n",
      "Step [83/271], Loss: 3.0161, Dealed Nodes [1861/2709] \n",
      "Step [84/271], Loss: 3.0282, Dealed Nodes [1878/2709] \n",
      "Step [85/271], Loss: 3.0186, Dealed Nodes [1887/2709] \n",
      "Step [86/271], Loss: 3.0263, Dealed Nodes [1896/2709] \n",
      "Step [87/271], Loss: 3.0122, Dealed Nodes [1905/2709] \n",
      "Step [88/271], Loss: 3.0214, Dealed Nodes [1911/2709] \n",
      "Step [89/271], Loss: 3.0181, Dealed Nodes [1919/2709] \n",
      "Step [90/271], Loss: 3.0251, Dealed Nodes [1926/2709] \n",
      "Step [91/271], Loss: 3.0167, Dealed Nodes [1934/2709] \n",
      "Step [92/271], Loss: 3.0222, Dealed Nodes [1940/2709] \n",
      "Step [93/271], Loss: 3.0149, Dealed Nodes [1953/2709] \n",
      "Step [94/271], Loss: 3.0197, Dealed Nodes [1964/2709] \n",
      "Step [95/271], Loss: 3.0150, Dealed Nodes [1978/2709] \n",
      "Step [96/271], Loss: 3.0231, Dealed Nodes [1983/2709] \n",
      "Step [97/271], Loss: 3.0081, Dealed Nodes [1990/2709] \n",
      "Step [98/271], Loss: 3.0155, Dealed Nodes [2002/2709] \n",
      "Step [99/271], Loss: 3.0124, Dealed Nodes [2007/2709] \n",
      "Step [100/271], Loss: 3.0151, Dealed Nodes [2015/2709] \n",
      "Step [101/271], Loss: 3.0080, Dealed Nodes [2023/2709] \n",
      "Step [102/271], Loss: 3.0169, Dealed Nodes [2033/2709] \n",
      "Step [103/271], Loss: 3.0132, Dealed Nodes [2043/2709] \n",
      "Step [104/271], Loss: 3.0107, Dealed Nodes [2049/2709] \n",
      "Step [105/271], Loss: 3.0116, Dealed Nodes [2055/2709] \n",
      "Step [106/271], Loss: 3.0317, Dealed Nodes [2066/2709] \n",
      "Step [107/271], Loss: 3.0142, Dealed Nodes [2072/2709] \n",
      "Step [108/271], Loss: 3.0099, Dealed Nodes [2082/2709] \n",
      "Step [109/271], Loss: 3.0170, Dealed Nodes [2092/2709] \n",
      "Step [110/271], Loss: 3.0096, Dealed Nodes [2100/2709] \n",
      "Step [111/271], Loss: 3.0141, Dealed Nodes [2106/2709] \n",
      "Step [112/271], Loss: 3.0164, Dealed Nodes [2114/2709] \n",
      "Step [113/271], Loss: 3.0134, Dealed Nodes [2122/2709] \n",
      "Step [114/271], Loss: 3.0122, Dealed Nodes [2129/2709] \n",
      "Step [115/271], Loss: 3.0109, Dealed Nodes [2135/2709] \n",
      "Step [116/271], Loss: 3.0165, Dealed Nodes [2144/2709] \n",
      "Step [117/271], Loss: 3.0110, Dealed Nodes [2153/2709] \n",
      "Step [118/271], Loss: 3.0116, Dealed Nodes [2160/2709] \n",
      "Step [119/271], Loss: 3.0167, Dealed Nodes [2166/2709] \n",
      "Step [120/271], Loss: 3.0090, Dealed Nodes [2175/2709] \n",
      "Step [121/271], Loss: 3.0201, Dealed Nodes [2177/2709] \n",
      "Step [122/271], Loss: 3.0164, Dealed Nodes [2181/2709] \n",
      "Step [123/271], Loss: 3.0088, Dealed Nodes [2188/2709] \n",
      "Step [124/271], Loss: 3.0138, Dealed Nodes [2191/2709] \n",
      "Step [125/271], Loss: 3.0124, Dealed Nodes [2196/2709] \n",
      "Step [126/271], Loss: 3.0068, Dealed Nodes [2199/2709] \n",
      "Step [127/271], Loss: 3.0159, Dealed Nodes [2205/2709] \n",
      "Step [128/271], Loss: 3.0245, Dealed Nodes [2207/2709] \n",
      "Step [129/271], Loss: 3.0062, Dealed Nodes [2211/2709] \n",
      "Step [130/271], Loss: 3.0127, Dealed Nodes [2216/2709] \n",
      "Step [131/271], Loss: 3.0037, Dealed Nodes [2221/2709] \n",
      "Step [132/271], Loss: 3.0174, Dealed Nodes [2227/2709] \n",
      "Step [133/271], Loss: 3.0056, Dealed Nodes [2238/2709] \n",
      "Step [134/271], Loss: 3.0136, Dealed Nodes [2241/2709] \n",
      "Step [135/271], Loss: 3.0183, Dealed Nodes [2245/2709] \n",
      "Step [136/271], Loss: 3.0091, Dealed Nodes [2252/2709] \n",
      "Step [137/271], Loss: 3.0101, Dealed Nodes [2254/2709] \n",
      "Step [138/271], Loss: 3.0088, Dealed Nodes [2261/2709] \n",
      "Step [139/271], Loss: 3.0160, Dealed Nodes [2271/2709] \n",
      "Step [140/271], Loss: 3.0111, Dealed Nodes [2276/2709] \n",
      "Step [141/271], Loss: 3.0125, Dealed Nodes [2280/2709] \n",
      "Step [142/271], Loss: 3.0086, Dealed Nodes [2284/2709] \n",
      "Step [143/271], Loss: 3.0133, Dealed Nodes [2289/2709] \n",
      "Step [144/271], Loss: 3.0167, Dealed Nodes [2297/2709] \n",
      "Step [145/271], Loss: 3.0028, Dealed Nodes [2300/2709] \n",
      "Step [146/271], Loss: 3.0110, Dealed Nodes [2305/2709] \n",
      "Step [147/271], Loss: 3.0104, Dealed Nodes [2309/2709] \n",
      "Step [148/271], Loss: 3.0175, Dealed Nodes [2315/2709] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [149/271], Loss: 3.0106, Dealed Nodes [2320/2709] \n",
      "Step [150/271], Loss: 3.0136, Dealed Nodes [2324/2709] \n",
      "Step [151/271], Loss: 3.0072, Dealed Nodes [2334/2709] \n",
      "Step [152/271], Loss: 3.0091, Dealed Nodes [2341/2709] \n",
      "Step [153/271], Loss: 3.0105, Dealed Nodes [2348/2709] \n",
      "Step [154/271], Loss: 3.0095, Dealed Nodes [2352/2709] \n",
      "Step [155/271], Loss: 3.0087, Dealed Nodes [2356/2709] \n",
      "Step [156/271], Loss: 3.0123, Dealed Nodes [2360/2709] \n",
      "Step [157/271], Loss: 3.0092, Dealed Nodes [2368/2709] \n",
      "Step [158/271], Loss: 3.0110, Dealed Nodes [2374/2709] \n",
      "Step [159/271], Loss: 3.0105, Dealed Nodes [2377/2709] \n",
      "Step [160/271], Loss: 3.0100, Dealed Nodes [2380/2709] \n",
      "Step [161/271], Loss: 3.0066, Dealed Nodes [2386/2709] \n",
      "Step [162/271], Loss: 3.0097, Dealed Nodes [2389/2709] \n",
      "Step [163/271], Loss: 3.0092, Dealed Nodes [2392/2709] \n",
      "Step [164/271], Loss: 3.0156, Dealed Nodes [2396/2709] \n",
      "Step [165/271], Loss: 3.0146, Dealed Nodes [2404/2709] \n",
      "Step [166/271], Loss: 3.0169, Dealed Nodes [2407/2709] \n",
      "Step [167/271], Loss: 3.0121, Dealed Nodes [2413/2709] \n",
      "Step [168/271], Loss: 3.0146, Dealed Nodes [2417/2709] \n",
      "Step [169/271], Loss: 3.0111, Dealed Nodes [2422/2709] \n",
      "Step [170/271], Loss: 3.0137, Dealed Nodes [2425/2709] \n",
      "Step [171/271], Loss: 3.0127, Dealed Nodes [2427/2709] \n",
      "Step [172/271], Loss: 3.0090, Dealed Nodes [2428/2709] \n",
      "Step [173/271], Loss: 3.0124, Dealed Nodes [2433/2709] \n",
      "Step [174/271], Loss: 3.0050, Dealed Nodes [2436/2709] \n",
      "Step [175/271], Loss: 3.0082, Dealed Nodes [2437/2709] \n",
      "Step [176/271], Loss: 3.0072, Dealed Nodes [2440/2709] \n",
      "Step [177/271], Loss: 3.0058, Dealed Nodes [2447/2709] \n",
      "Step [178/271], Loss: 3.0126, Dealed Nodes [2451/2709] \n",
      "Step [179/271], Loss: 3.0051, Dealed Nodes [2453/2709] \n",
      "Step [180/271], Loss: 3.0179, Dealed Nodes [2455/2709] \n",
      "Step [181/271], Loss: 3.0144, Dealed Nodes [2458/2709] \n",
      "Step [182/271], Loss: 3.0105, Dealed Nodes [2461/2709] \n",
      "Step [183/271], Loss: 3.0144, Dealed Nodes [2462/2709] \n",
      "Step [184/271], Loss: 3.0092, Dealed Nodes [2466/2709] \n",
      "Step [185/271], Loss: 3.0091, Dealed Nodes [2469/2709] \n",
      "Step [186/271], Loss: 3.0136, Dealed Nodes [2473/2709] \n",
      "Step [187/271], Loss: 3.0071, Dealed Nodes [2476/2709] \n",
      "Step [188/271], Loss: 3.0132, Dealed Nodes [2480/2709] \n",
      "Step [189/271], Loss: 3.0079, Dealed Nodes [2482/2709] \n",
      "Step [190/271], Loss: 3.0055, Dealed Nodes [2486/2709] \n",
      "Step [191/271], Loss: 3.0095, Dealed Nodes [2489/2709] \n",
      "Step [192/271], Loss: 3.0116, Dealed Nodes [2491/2709] \n",
      "Step [193/271], Loss: 3.0102, Dealed Nodes [2492/2709] \n",
      "Step [194/271], Loss: 3.0133, Dealed Nodes [2497/2709] \n",
      "Step [195/271], Loss: 3.0133, Dealed Nodes [2500/2709] \n",
      "Step [196/271], Loss: 3.0053, Dealed Nodes [2503/2709] \n",
      "Step [197/271], Loss: 3.0120, Dealed Nodes [2505/2709] \n",
      "Step [198/271], Loss: 3.0061, Dealed Nodes [2509/2709] \n",
      "Step [199/271], Loss: 3.0126, Dealed Nodes [2514/2709] \n",
      "Step [200/271], Loss: 3.0185, Dealed Nodes [2518/2709] \n",
      "Step [201/271], Loss: 3.0087, Dealed Nodes [2520/2709] \n",
      "Step [202/271], Loss: 3.0057, Dealed Nodes [2521/2709] \n",
      "Step [203/271], Loss: 3.0064, Dealed Nodes [2527/2709] \n",
      "Step [204/271], Loss: 3.0092, Dealed Nodes [2529/2709] \n",
      "Step [205/271], Loss: 3.0075, Dealed Nodes [2533/2709] \n",
      "Step [206/271], Loss: 3.0091, Dealed Nodes [2535/2709] \n",
      "Step [207/271], Loss: 3.0007, Dealed Nodes [2540/2709] \n",
      "Step [208/271], Loss: 3.0078, Dealed Nodes [2543/2709] \n",
      "Step [209/271], Loss: 3.0093, Dealed Nodes [2545/2709] \n",
      "Step [210/271], Loss: 3.0099, Dealed Nodes [2547/2709] \n",
      "Step [211/271], Loss: 3.0079, Dealed Nodes [2548/2709] \n",
      "Step [212/271], Loss: 3.0048, Dealed Nodes [2549/2709] \n",
      "Step [213/271], Loss: 3.0115, Dealed Nodes [2551/2709] \n",
      "Step [214/271], Loss: 3.0127, Dealed Nodes [2555/2709] \n",
      "Step [215/271], Loss: 3.0077, Dealed Nodes [2557/2709] \n",
      "Step [216/271], Loss: 3.0123, Dealed Nodes [2562/2709] \n",
      "Step [217/271], Loss: 3.0058, Dealed Nodes [2564/2709] \n",
      "Step [218/271], Loss: 3.0167, Dealed Nodes [2568/2709] \n",
      "Step [219/271], Loss: 3.0012, Dealed Nodes [2571/2709] \n",
      "Step [220/271], Loss: 3.0101, Dealed Nodes [2573/2709] \n",
      "Step [221/271], Loss: 3.0092, Dealed Nodes [2576/2709] \n",
      "Step [222/271], Loss: 3.0051, Dealed Nodes [2582/2709] \n",
      "Step [223/271], Loss: 3.0058, Dealed Nodes [2585/2709] \n",
      "Step [224/271], Loss: 3.0108, Dealed Nodes [2587/2709] \n",
      "Step [225/271], Loss: 3.0057, Dealed Nodes [2591/2709] \n",
      "Step [226/271], Loss: 3.0113, Dealed Nodes [2593/2709] \n",
      "Step [227/271], Loss: 3.0057, Dealed Nodes [2600/2709] \n",
      "Step [228/271], Loss: 3.0100, Dealed Nodes [2602/2709] \n",
      "Step [229/271], Loss: 3.0005, Dealed Nodes [2603/2709] \n",
      "Step [230/271], Loss: 3.0108, Dealed Nodes [2607/2709] \n",
      "Step [231/271], Loss: 3.0071, Dealed Nodes [2610/2709] \n",
      "Step [232/271], Loss: 3.0064, Dealed Nodes [2612/2709] \n",
      "Step [233/271], Loss: 2.9991, Dealed Nodes [2616/2709] \n",
      "Step [234/271], Loss: 3.0060, Dealed Nodes [2618/2709] \n",
      "Step [235/271], Loss: 3.0060, Dealed Nodes [2621/2709] \n",
      "Step [236/271], Loss: 3.0027, Dealed Nodes [2624/2709] \n",
      "Step [237/271], Loss: 3.0102, Dealed Nodes [2628/2709] \n",
      "Step [238/271], Loss: 3.0129, Dealed Nodes [2632/2709] \n",
      "Step [239/271], Loss: 3.0092, Dealed Nodes [2635/2709] \n",
      "Step [240/271], Loss: 3.0088, Dealed Nodes [2638/2709] \n",
      "Step [241/271], Loss: 3.0008, Dealed Nodes [2643/2709] \n",
      "Step [242/271], Loss: 3.0096, Dealed Nodes [2644/2709] \n",
      "Step [243/271], Loss: 3.0085, Dealed Nodes [2646/2709] \n",
      "Step [244/271], Loss: 3.0006, Dealed Nodes [2647/2709] \n",
      "Step [245/271], Loss: 3.0143, Dealed Nodes [2651/2709] \n",
      "Step [246/271], Loss: 3.0096, Dealed Nodes [2651/2709] \n",
      "Step [247/271], Loss: 3.0155, Dealed Nodes [2654/2709] \n",
      "Step [248/271], Loss: 3.0011, Dealed Nodes [2659/2709] \n",
      "Step [249/271], Loss: 3.0044, Dealed Nodes [2661/2709] \n",
      "Step [250/271], Loss: 3.0134, Dealed Nodes [2665/2709] \n",
      "Step [251/271], Loss: 3.0031, Dealed Nodes [2667/2709] \n",
      "Step [252/271], Loss: 3.0104, Dealed Nodes [2670/2709] \n",
      "Step [253/271], Loss: 3.0068, Dealed Nodes [2671/2709] \n",
      "Step [254/271], Loss: 3.0031, Dealed Nodes [2672/2709] \n",
      "Step [255/271], Loss: 3.0014, Dealed Nodes [2674/2709] \n",
      "Step [256/271], Loss: 3.0056, Dealed Nodes [2676/2709] \n",
      "Step [257/271], Loss: 3.0026, Dealed Nodes [2676/2709] \n",
      "Step [258/271], Loss: 3.0112, Dealed Nodes [2676/2709] \n",
      "Step [259/271], Loss: 3.0091, Dealed Nodes [2677/2709] \n",
      "Step [260/271], Loss: 3.0040, Dealed Nodes [2683/2709] \n",
      "Step [261/271], Loss: 3.0003, Dealed Nodes [2684/2709] \n",
      "Step [262/271], Loss: 3.0173, Dealed Nodes [2686/2709] \n",
      "Step [263/271], Loss: 3.0053, Dealed Nodes [2690/2709] \n",
      "Step [264/271], Loss: 3.0034, Dealed Nodes [2691/2709] \n",
      "Step [265/271], Loss: 3.0042, Dealed Nodes [2692/2709] \n",
      "Step [266/271], Loss: 3.0029, Dealed Nodes [2696/2709] \n",
      "Step [267/271], Loss: 3.0017, Dealed Nodes [2697/2709] \n",
      "Step [268/271], Loss: 3.0058, Dealed Nodes [2698/2709] \n",
      "Step [269/271], Loss: 3.0032, Dealed Nodes [2704/2709] \n",
      "Step [270/271], Loss: 3.0050, Dealed Nodes [2706/2709] \n",
      "Step [271/271], Loss: 2.9995, Dealed Nodes [2709/2709] \n",
      "----------------------EPOCH 1-----------------------\n",
      "Step [1/271], Loss: 3.0078, Dealed Nodes [68/2709] \n",
      "Step [2/271], Loss: 3.0064, Dealed Nodes [124/2709] \n",
      "Step [3/271], Loss: 3.0030, Dealed Nodes [182/2709] \n",
      "Step [4/271], Loss: 3.0045, Dealed Nodes [230/2709] \n",
      "Step [5/271], Loss: 3.0137, Dealed Nodes [275/2709] \n",
      "Step [6/271], Loss: 3.0009, Dealed Nodes [319/2709] \n",
      "Step [7/271], Loss: 3.0074, Dealed Nodes [364/2709] \n",
      "Step [8/271], Loss: 3.0065, Dealed Nodes [408/2709] \n",
      "Step [9/271], Loss: 3.0103, Dealed Nodes [458/2709] \n",
      "Step [10/271], Loss: 3.0043, Dealed Nodes [497/2709] \n",
      "Step [11/271], Loss: 3.0109, Dealed Nodes [527/2709] \n",
      "Step [12/271], Loss: 3.0082, Dealed Nodes [568/2709] \n",
      "Step [13/271], Loss: 3.0143, Dealed Nodes [607/2709] \n",
      "Step [14/271], Loss: 3.0048, Dealed Nodes [638/2709] \n",
      "Step [15/271], Loss: 3.0048, Dealed Nodes [662/2709] \n",
      "Step [16/271], Loss: 3.0097, Dealed Nodes [697/2709] \n",
      "Step [17/271], Loss: 3.0064, Dealed Nodes [731/2709] \n",
      "Step [18/271], Loss: 3.0102, Dealed Nodes [754/2709] \n",
      "Step [19/271], Loss: 3.0072, Dealed Nodes [789/2709] \n",
      "Step [20/271], Loss: 3.0082, Dealed Nodes [811/2709] \n",
      "Step [21/271], Loss: 3.0074, Dealed Nodes [836/2709] \n",
      "Step [22/271], Loss: 3.0063, Dealed Nodes [861/2709] \n",
      "Step [23/271], Loss: 3.0046, Dealed Nodes [881/2709] \n",
      "Step [24/271], Loss: 3.0011, Dealed Nodes [900/2709] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [25/271], Loss: 3.0080, Dealed Nodes [930/2709] \n",
      "Step [26/271], Loss: 3.0078, Dealed Nodes [956/2709] \n",
      "Step [27/271], Loss: 2.9973, Dealed Nodes [985/2709] \n",
      "Step [28/271], Loss: 3.0014, Dealed Nodes [1011/2709] \n",
      "Step [29/271], Loss: 3.0075, Dealed Nodes [1027/2709] \n",
      "Step [30/271], Loss: 3.0017, Dealed Nodes [1049/2709] \n",
      "Step [31/271], Loss: 3.0029, Dealed Nodes [1072/2709] \n",
      "Step [32/271], Loss: 3.0081, Dealed Nodes [1095/2709] \n",
      "Step [33/271], Loss: 3.0095, Dealed Nodes [1115/2709] \n",
      "Step [34/271], Loss: 3.0001, Dealed Nodes [1134/2709] \n",
      "Step [35/271], Loss: 3.0011, Dealed Nodes [1160/2709] \n",
      "Step [36/271], Loss: 3.0228, Dealed Nodes [1180/2709] \n",
      "Step [37/271], Loss: 3.0054, Dealed Nodes [1192/2709] \n",
      "Step [38/271], Loss: 3.0055, Dealed Nodes [1218/2709] \n",
      "Step [39/271], Loss: 3.0099, Dealed Nodes [1238/2709] \n",
      "Step [40/271], Loss: 3.0066, Dealed Nodes [1252/2709] \n",
      "Step [41/271], Loss: 3.0092, Dealed Nodes [1271/2709] \n",
      "Step [42/271], Loss: 3.0002, Dealed Nodes [1283/2709] \n",
      "Step [43/271], Loss: 3.0063, Dealed Nodes [1296/2709] \n",
      "Step [44/271], Loss: 3.0048, Dealed Nodes [1318/2709] \n",
      "Step [45/271], Loss: 3.0058, Dealed Nodes [1336/2709] \n",
      "Step [46/271], Loss: 3.0021, Dealed Nodes [1354/2709] \n",
      "Step [47/271], Loss: 3.0021, Dealed Nodes [1376/2709] \n",
      "Step [48/271], Loss: 3.0028, Dealed Nodes [1401/2709] \n",
      "Step [49/271], Loss: 3.0015, Dealed Nodes [1414/2709] \n",
      "Step [50/271], Loss: 2.9979, Dealed Nodes [1430/2709] \n",
      "Step [51/271], Loss: 2.9984, Dealed Nodes [1446/2709] \n",
      "Step [52/271], Loss: 2.9995, Dealed Nodes [1463/2709] \n",
      "Step [53/271], Loss: 2.9981, Dealed Nodes [1475/2709] \n",
      "Step [54/271], Loss: 3.0084, Dealed Nodes [1487/2709] \n",
      "Step [55/271], Loss: 2.9973, Dealed Nodes [1499/2709] \n",
      "Step [56/271], Loss: 3.0094, Dealed Nodes [1514/2709] \n",
      "Step [57/271], Loss: 3.0059, Dealed Nodes [1528/2709] \n",
      "Step [58/271], Loss: 3.0109, Dealed Nodes [1551/2709] \n",
      "Step [59/271], Loss: 3.0026, Dealed Nodes [1570/2709] \n",
      "Step [60/271], Loss: 3.0046, Dealed Nodes [1583/2709] \n",
      "Step [61/271], Loss: 3.0040, Dealed Nodes [1599/2709] \n",
      "Step [62/271], Loss: 3.0085, Dealed Nodes [1605/2709] \n",
      "Step [63/271], Loss: 3.0036, Dealed Nodes [1623/2709] \n",
      "Step [64/271], Loss: 3.0005, Dealed Nodes [1633/2709] \n",
      "Step [65/271], Loss: 3.0088, Dealed Nodes [1646/2709] \n",
      "Step [66/271], Loss: 3.0018, Dealed Nodes [1664/2709] \n",
      "Step [67/271], Loss: 3.0079, Dealed Nodes [1681/2709] \n",
      "Step [68/271], Loss: 2.9990, Dealed Nodes [1692/2709] \n",
      "Step [69/271], Loss: 3.0046, Dealed Nodes [1711/2709] \n",
      "Step [70/271], Loss: 3.0040, Dealed Nodes [1726/2709] \n",
      "Step [71/271], Loss: 2.9998, Dealed Nodes [1735/2709] \n",
      "Step [72/271], Loss: 3.0060, Dealed Nodes [1743/2709] \n",
      "Step [73/271], Loss: 3.0080, Dealed Nodes [1755/2709] \n",
      "Step [74/271], Loss: 3.0029, Dealed Nodes [1765/2709] \n",
      "Step [75/271], Loss: 3.0000, Dealed Nodes [1777/2709] \n",
      "Step [76/271], Loss: 3.0068, Dealed Nodes [1789/2709] \n",
      "Step [77/271], Loss: 3.0039, Dealed Nodes [1804/2709] \n",
      "Step [78/271], Loss: 3.0081, Dealed Nodes [1815/2709] \n",
      "Step [79/271], Loss: 3.0064, Dealed Nodes [1822/2709] \n",
      "Step [80/271], Loss: 3.0033, Dealed Nodes [1831/2709] \n",
      "Step [81/271], Loss: 3.0032, Dealed Nodes [1843/2709] \n",
      "Step [82/271], Loss: 3.0004, Dealed Nodes [1853/2709] \n",
      "Step [83/271], Loss: 3.0031, Dealed Nodes [1863/2709] \n",
      "Step [84/271], Loss: 3.0025, Dealed Nodes [1870/2709] \n",
      "Step [85/271], Loss: 2.9973, Dealed Nodes [1878/2709] \n",
      "Step [86/271], Loss: 3.0008, Dealed Nodes [1885/2709] \n",
      "Step [87/271], Loss: 3.0042, Dealed Nodes [1894/2709] \n",
      "Step [88/271], Loss: 3.0092, Dealed Nodes [1913/2709] \n",
      "Step [89/271], Loss: 3.0000, Dealed Nodes [1917/2709] \n",
      "Step [90/271], Loss: 2.9979, Dealed Nodes [1923/2709] \n",
      "Step [91/271], Loss: 3.0046, Dealed Nodes [1933/2709] \n",
      "Step [92/271], Loss: 2.9974, Dealed Nodes [1944/2709] \n",
      "Step [93/271], Loss: 3.0064, Dealed Nodes [1951/2709] \n",
      "Step [94/271], Loss: 2.9957, Dealed Nodes [1960/2709] \n",
      "Step [95/271], Loss: 3.0011, Dealed Nodes [1967/2709] \n",
      "Step [96/271], Loss: 3.0059, Dealed Nodes [1972/2709] \n",
      "Step [97/271], Loss: 2.9990, Dealed Nodes [1984/2709] \n",
      "Step [98/271], Loss: 3.0026, Dealed Nodes [1995/2709] \n",
      "Step [99/271], Loss: 3.0047, Dealed Nodes [2008/2709] \n",
      "Step [100/271], Loss: 2.9985, Dealed Nodes [2019/2709] \n",
      "Step [101/271], Loss: 3.0006, Dealed Nodes [2028/2709] \n",
      "Step [102/271], Loss: 2.9962, Dealed Nodes [2036/2709] \n",
      "Step [103/271], Loss: 3.0063, Dealed Nodes [2043/2709] \n",
      "Step [104/271], Loss: 2.9999, Dealed Nodes [2046/2709] \n",
      "Step [105/271], Loss: 3.0020, Dealed Nodes [2052/2709] \n",
      "Step [106/271], Loss: 3.0002, Dealed Nodes [2057/2709] \n",
      "Step [107/271], Loss: 3.0046, Dealed Nodes [2066/2709] \n",
      "Step [108/271], Loss: 3.0003, Dealed Nodes [2074/2709] \n",
      "Step [109/271], Loss: 2.9987, Dealed Nodes [2079/2709] \n",
      "Step [110/271], Loss: 2.9993, Dealed Nodes [2090/2709] \n",
      "Step [111/271], Loss: 3.0092, Dealed Nodes [2096/2709] \n",
      "Step [112/271], Loss: 2.9984, Dealed Nodes [2107/2709] \n",
      "Step [113/271], Loss: 3.0015, Dealed Nodes [2113/2709] \n",
      "Step [114/271], Loss: 3.0013, Dealed Nodes [2120/2709] \n",
      "Step [115/271], Loss: 2.9970, Dealed Nodes [2124/2709] \n",
      "Step [116/271], Loss: 3.0041, Dealed Nodes [2128/2709] \n",
      "Step [117/271], Loss: 3.0043, Dealed Nodes [2136/2709] \n",
      "Step [118/271], Loss: 3.0072, Dealed Nodes [2140/2709] \n",
      "Step [119/271], Loss: 3.0012, Dealed Nodes [2146/2709] \n",
      "Step [120/271], Loss: 2.9958, Dealed Nodes [2150/2709] \n",
      "Step [121/271], Loss: 2.9997, Dealed Nodes [2157/2709] \n",
      "Step [122/271], Loss: 2.9958, Dealed Nodes [2162/2709] \n",
      "Step [123/271], Loss: 2.9951, Dealed Nodes [2169/2709] \n",
      "Step [124/271], Loss: 3.0001, Dealed Nodes [2175/2709] \n",
      "Step [125/271], Loss: 3.0031, Dealed Nodes [2178/2709] \n",
      "Step [126/271], Loss: 2.9980, Dealed Nodes [2185/2709] \n",
      "Step [127/271], Loss: 3.0014, Dealed Nodes [2193/2709] \n",
      "Step [128/271], Loss: 3.0049, Dealed Nodes [2197/2709] \n",
      "Step [129/271], Loss: 3.0036, Dealed Nodes [2200/2709] \n",
      "Step [130/271], Loss: 3.0021, Dealed Nodes [2208/2709] \n",
      "Step [131/271], Loss: 2.9944, Dealed Nodes [2212/2709] \n",
      "Step [132/271], Loss: 2.9965, Dealed Nodes [2216/2709] \n",
      "Step [133/271], Loss: 2.9949, Dealed Nodes [2224/2709] \n",
      "Step [134/271], Loss: 3.0011, Dealed Nodes [2227/2709] \n",
      "Step [135/271], Loss: 2.9993, Dealed Nodes [2234/2709] \n",
      "Step [136/271], Loss: 3.0009, Dealed Nodes [2244/2709] \n",
      "Step [137/271], Loss: 3.0013, Dealed Nodes [2248/2709] \n",
      "Step [138/271], Loss: 2.9952, Dealed Nodes [2255/2709] \n",
      "Step [139/271], Loss: 3.0020, Dealed Nodes [2263/2709] \n",
      "Step [140/271], Loss: 3.0003, Dealed Nodes [2267/2709] \n",
      "Step [141/271], Loss: 3.0018, Dealed Nodes [2272/2709] \n",
      "Step [142/271], Loss: 2.9949, Dealed Nodes [2277/2709] \n",
      "Step [143/271], Loss: 3.0038, Dealed Nodes [2282/2709] \n",
      "Step [144/271], Loss: 2.9923, Dealed Nodes [2288/2709] \n",
      "Step [145/271], Loss: 2.9991, Dealed Nodes [2295/2709] \n",
      "Step [146/271], Loss: 2.9981, Dealed Nodes [2299/2709] \n",
      "Step [147/271], Loss: 2.9942, Dealed Nodes [2307/2709] \n",
      "Step [148/271], Loss: 2.9956, Dealed Nodes [2315/2709] \n",
      "Step [149/271], Loss: 2.9922, Dealed Nodes [2319/2709] \n",
      "Step [150/271], Loss: 2.9993, Dealed Nodes [2324/2709] \n",
      "Step [151/271], Loss: 2.9932, Dealed Nodes [2327/2709] \n",
      "Step [152/271], Loss: 3.0080, Dealed Nodes [2333/2709] \n",
      "Step [153/271], Loss: 2.9984, Dealed Nodes [2338/2709] \n",
      "Step [154/271], Loss: 2.9958, Dealed Nodes [2343/2709] \n",
      "Step [155/271], Loss: 3.0018, Dealed Nodes [2346/2709] \n",
      "Step [156/271], Loss: 3.0047, Dealed Nodes [2350/2709] \n",
      "Step [157/271], Loss: 2.9961, Dealed Nodes [2358/2709] \n",
      "Step [158/271], Loss: 2.9976, Dealed Nodes [2365/2709] \n",
      "Step [159/271], Loss: 2.9956, Dealed Nodes [2369/2709] \n",
      "Step [160/271], Loss: 3.0011, Dealed Nodes [2375/2709] \n",
      "Step [161/271], Loss: 2.9946, Dealed Nodes [2378/2709] \n",
      "Step [162/271], Loss: 3.0011, Dealed Nodes [2382/2709] \n",
      "Step [163/271], Loss: 2.9917, Dealed Nodes [2385/2709] \n",
      "Step [164/271], Loss: 2.9977, Dealed Nodes [2390/2709] \n",
      "Step [165/271], Loss: 2.9910, Dealed Nodes [2397/2709] \n",
      "Step [166/271], Loss: 3.0017, Dealed Nodes [2401/2709] \n",
      "Step [167/271], Loss: 3.0015, Dealed Nodes [2406/2709] \n",
      "Step [168/271], Loss: 2.9962, Dealed Nodes [2411/2709] \n",
      "Step [169/271], Loss: 2.9960, Dealed Nodes [2413/2709] \n",
      "Step [170/271], Loss: 2.9965, Dealed Nodes [2420/2709] \n",
      "Step [171/271], Loss: 2.9970, Dealed Nodes [2424/2709] \n",
      "Step [172/271], Loss: 2.9880, Dealed Nodes [2428/2709] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [173/271], Loss: 2.9962, Dealed Nodes [2435/2709] \n",
      "Step [174/271], Loss: 2.9955, Dealed Nodes [2439/2709] \n",
      "Step [175/271], Loss: 3.0027, Dealed Nodes [2444/2709] \n",
      "Step [176/271], Loss: 2.9906, Dealed Nodes [2454/2709] \n",
      "Step [177/271], Loss: 2.9897, Dealed Nodes [2458/2709] \n",
      "Step [178/271], Loss: 3.0014, Dealed Nodes [2463/2709] \n",
      "Step [179/271], Loss: 2.9894, Dealed Nodes [2467/2709] \n",
      "Step [180/271], Loss: 2.9947, Dealed Nodes [2469/2709] \n",
      "Step [181/271], Loss: 2.9937, Dealed Nodes [2472/2709] \n",
      "Step [182/271], Loss: 2.9867, Dealed Nodes [2481/2709] \n",
      "Step [183/271], Loss: 2.9906, Dealed Nodes [2483/2709] \n",
      "Step [184/271], Loss: 2.9963, Dealed Nodes [2487/2709] \n",
      "Step [185/271], Loss: 2.9947, Dealed Nodes [2493/2709] \n",
      "Step [186/271], Loss: 2.9875, Dealed Nodes [2495/2709] \n",
      "Step [187/271], Loss: 2.9977, Dealed Nodes [2498/2709] \n",
      "Step [188/271], Loss: 2.9928, Dealed Nodes [2502/2709] \n",
      "Step [189/271], Loss: 2.9897, Dealed Nodes [2504/2709] \n",
      "Step [190/271], Loss: 2.9969, Dealed Nodes [2506/2709] \n",
      "Step [191/271], Loss: 2.9941, Dealed Nodes [2510/2709] \n",
      "Step [192/271], Loss: 2.9947, Dealed Nodes [2514/2709] \n",
      "Step [193/271], Loss: 2.9941, Dealed Nodes [2519/2709] \n",
      "Step [194/271], Loss: 2.9922, Dealed Nodes [2523/2709] \n",
      "Step [195/271], Loss: 2.9860, Dealed Nodes [2530/2709] \n",
      "Step [196/271], Loss: 2.9862, Dealed Nodes [2534/2709] \n",
      "Step [197/271], Loss: 2.9951, Dealed Nodes [2537/2709] \n",
      "Step [198/271], Loss: 2.9882, Dealed Nodes [2540/2709] \n",
      "Step [199/271], Loss: 2.9922, Dealed Nodes [2543/2709] \n",
      "Step [200/271], Loss: 2.9868, Dealed Nodes [2547/2709] \n",
      "Step [201/271], Loss: 2.9863, Dealed Nodes [2549/2709] \n",
      "Step [202/271], Loss: 2.9887, Dealed Nodes [2552/2709] \n",
      "Step [203/271], Loss: 2.9928, Dealed Nodes [2555/2709] \n",
      "Step [204/271], Loss: 2.9848, Dealed Nodes [2557/2709] \n",
      "Step [205/271], Loss: 2.9935, Dealed Nodes [2562/2709] \n",
      "Step [206/271], Loss: 2.9913, Dealed Nodes [2566/2709] \n",
      "Step [207/271], Loss: 2.9925, Dealed Nodes [2570/2709] \n",
      "Step [208/271], Loss: 2.9888, Dealed Nodes [2573/2709] \n",
      "Step [209/271], Loss: 2.9817, Dealed Nodes [2576/2709] \n",
      "Step [210/271], Loss: 2.9751, Dealed Nodes [2580/2709] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b527f3acd207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mvisited_nodes\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0membs_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphSage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munsupervised_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loss_margin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membs_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Step [{}/{}], Loss: {:.4f}, Dealed Nodes [{}/{}] '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisited_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda\\envs\\sds20\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\200_CASA\\33_D\\model\\GraphSAGE.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, nodes_batch)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mlower_layer_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamp_edges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lower_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupper_layer_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mnodes_batch_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlower_layer_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamp_edges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mupper_layer_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlower_layer_nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\200_CASA\\33_D\\model\\GraphSAGE.py\u001b[0m in \u001b[0;36mget_lower_layer\u001b[1;34m(self, nodes_batch, sample_num)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[0msamp_edges\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfrom_node_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mto_node_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_edges\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mint\u001b[0m \u001b[0mtentor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \"\"\"\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0madj_lists_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reverse_adj_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[0mto_neighs_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0madj_lists_r\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodes_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0msamp_neighs_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_neighs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_neighs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0msample_num\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mto_neighs\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mto_neighs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_neighs_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\200_CASA\\33_D\\model\\GraphSAGE.py\u001b[0m in \u001b[0;36mget_reverse_adj_list\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj_lists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                 \u001b[0madj_lists_r\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0madj_lists_r\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = {\"seed\":43,\n",
    "        \"num_layers\":2,\n",
    "        \"batch_size\":10,\n",
    "        \"num_neg\":10,\n",
    "        \"num_epochs\":50,\n",
    "        \"lr\":0.5,\n",
    "        \"input_dim\":60,\n",
    "        \"output_dim\":20}\n",
    "\n",
    "random.seed(args[\"seed\"])\n",
    "np.random.seed(args[\"seed\"])\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "graphSage = GraphSage(args[\"input_dim\"],  # agg_feature_dim\n",
    "                      args[\"output_dim\"],  # node_hidden_dim\n",
    "                      nfeats1,\n",
    "                      efeats1,\n",
    "                      adj_lists, \n",
    "                      edgeid_to_idx,\n",
    "                      device)\n",
    "graphSage.to(device)\n",
    "\n",
    "unsupervised_loss = UnsupervisedLoss(adj_lists, nodes , device)\n",
    "\n",
    "for epoch in range(args[\"num_epochs\"]):\n",
    "    print('----------------------EPOCH %d-----------------------' % epoch)\n",
    "    train_nodes = shuffle(nodes)\n",
    "    models = [graphSage]\n",
    "    params = []\n",
    "    for model in models:\n",
    "        for param in model.parameters():\n",
    "            if param.requires_grad:\n",
    "                params.append(param)\n",
    "\n",
    "    optimizer = torch.optim.SGD(params, lr=args[\"lr\"])\n",
    "    optimizer.zero_grad()\n",
    "    for model in models:\n",
    "        model.zero_grad()\n",
    "    \n",
    "    batches = math.ceil(len(train_nodes) / args[\"batch_size\"])\n",
    "    visited_nodes = set()\n",
    "\n",
    "    for index in range(batches):\n",
    "        nodes_batch = np.array(train_nodes[index*args[\"batch_size\"]:(index+1)*args[\"batch_size\"]])\n",
    "        \n",
    "        # extend nodes batch for unspervised learning\n",
    "        nodes_batch = np.asarray(list(unsupervised_loss.extend_nodes(nodes_batch, num_neg=args[\"num_neg\"])))\n",
    "        visited_nodes |= set(nodes_batch)\n",
    "        \n",
    "        embs_batch = graphSage(nodes_batch)\n",
    "        loss = unsupervised_loss.get_loss_margin(embs_batch, nodes_batch)\n",
    "        print('Step [{}/{}], Loss: {:.4f}, Dealed Nodes [{}/{}] '.format(index+1, batches, loss.item(), len(visited_nodes), len(train_nodes)))\n",
    "        loss.backward()\n",
    "        for model in models:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for model in models:\n",
    "            model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings = model(nodes).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71818182 0.07594937 0.         0.         0.04347826 0.\n",
      " 0.14285714 0.08888889]\n",
      "0.34317343173431736\n",
      "0.0278320804530523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import silhouette_score,confusion_matrix,accuracy_score,cohen_kappa_score\n",
    "\n",
    "node_subject = gdf_zoning.loc[dict_mapids.keys(),\"zone_c\"].astype(\"category\").cat.codes\n",
    "\n",
    "# X = node_embeddings\n",
    "# if X.shape[1] > 2:\n",
    "#     transform = TSNE  # PCA\n",
    "\n",
    "#     trans = transform(n_components=2)\n",
    "#     emb_transformed = pd.DataFrame(trans.fit_transform(X), index=NODES)\n",
    "#     emb_transformed[\"lab\"] = node_subject\n",
    "# else:\n",
    "#     emb_transformed = pd.DataFrame(X, index=node_ids)\n",
    "#     emb_transformed = emb_transformed.rename(columns={\"0\": 0, \"1\": 1})\n",
    "#     emb_transformed[\"lab\"] = node_subject\n",
    "\n",
    "df_gnnvec = pd.DataFrame(node_embeddings)\n",
    "df_gnnvec[\"lab\"] = node_subject\n",
    "df_gnnvec.to_csv(\"result/torchgnn_vec.csv\",index=False)\n",
    "\n",
    "X = df_gnnvec[[i for i in range(20)]]\n",
    "y = df_gnnvec.lab.astype(\"category\").cat.codes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "acc = matrix.diagonal()/matrix.sum(axis=1)\n",
    "print(acc)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(cohen_kappa_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
